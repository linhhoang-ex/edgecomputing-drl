import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize, fsolve
import time as timer  


# Self-defined modules 
from utils import *                 # utility functions 
from system_paras import *          # System parameters 
from user import *                  # Load the class User 
from server import *                # Load the class Sever
from arrival_task import *          # Load the class ArrivalTask
from memoryTF2conv import * 

  
''' 
-----------------------------------------------------
Generate tasks and users 
-----------------------------------------------------
''' 
### only generate tasks and users if the files don't exist
if new_task_generation == True: 
    gen_tasks()       
    gen_users()


'''
-----------------------------------------------------
Initialize the neural network  
-----------------------------------------------------
'''
mem = MemoryDNN(net = [num_users*kernal_size, 256, 128, num_users*2],
                kernal_size = kernal_size,
                learning_rate = learning_rate,
                training_interval = training_interval,
                batch_size = batch_size,
                memory_size = Memory,
                loss_compute_interval=loss_compute_interval,
                epochs=epochs
                )
# export model's structure to an image
tf.keras.utils.plot_model(mem.model, to_file="model.png", show_shapes=True) 
# to get a summary of the model printed on the terminal 
mem.model.summary()


'''
-----------------------------------------------------
Load the neural network from json and h5 files   
-----------------------------------------------------
'''
# Load the trained model: .json (the model) -> .h5 (the parameters)
if load_pretrained_model==True: 
    from keras.models import model_from_json
    json_file = open(trained_model_filepath, 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights(trained_weights_filepath)    # load weights into new model
    loaded_model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss=tf.losses.binary_crossentropy, metrics=['accuracy'])
    mem.model = loaded_model 
    print("Loaded model from", trained_model_filepath, "and", trained_weights_filepath)
    
if selection_mode=='learning' and load_memory == True: 
    data_load = load_data( os.path.join(os.getcwd(), "memory.pickle") )
    mem.memory = data_load['memory']
    mem.memory_counter = mem.memory_size 


''' 
-----------------------------------------------------
Iterate over the MEC process 
-----------------------------------------------------
'''  
print("Sever selection mode: ", selection_mode)
mode_his = []       # store the offloading mode
k_idx_his = []      # store the index of optimal offloading actor
users = load_data(users_filepath)     # Load users from a file 
tasks = load_data(tasks_filepath)
for idx, user in enumerate(users):
    user.arrival_task = tasks.arrival_task[idx]
    user.qlen_thres = qlen_thres_user[idx]
server = Server(ncores=ncores)                   # Initiate the MEC server 

### => generate all feasible actions for offloading decision using brute-force search  
m_list_bf = server.gen_actions_bf()                                     
if is_n_actions_fixed == True: 
    n_actions = n_actions_fixed      # number of actions generated by the CNN   
else: 
    n_actions = int(n_actions_scale*m_list_bf.shape[0])
    
    
t_start = timer.time()
for t in range(0, time_max): 
    Qi_vec = np.array([user.queue_length[t] for user in users])         # shape = (num_users, )
    Li_vec = server.qlen[:, t].reshape(-1)                              # shape = (num_servers, )
    Hi_vec = np.array([user.channel_gain[t] for user in users])         # shape = (num_servers, ), channel gain of the user-UAV link
    Hi_BS_vec = np.array([user.channel_gain_BS[t] for user in users])   # shape = (num_servers, ), channel gain of the user-macro BS link
    VQ_local = np.array([user.vq_qlen_penalty[t] for user in users])    # shape = (num_users, ) 
    VQ_remote = server.vq_qlen_penalty[:,t].reshape(-1)                 # shape = (num_users, )
    
    # UAV: solve optimization problem -> update qlen and energy consumption 
    fcpu_uav_opt = server.opt_fcpu_uav(Li_vec, VQ_remote)
    
    #### 1) Actor module: generate a batch of actions 
    # scale the qlen and channel gain close to 1 
    if is_training_model==True:
        if isSklearnScalerActivated==False: 
            nn_input = np.vstack( (Hi_vec*CHFACT_UAV, Hi_BS_vec*CHFACT_BS, Qi_vec*QLFACT, Li_vec*QLFACT, VQ_local*QLFACT, VQ_remote*QLFACT) ).transpose().flatten()  # like [h1, hBS1, Q1, L1, h2, hBS2, Q2, L2, ...]
            nn_input_scale = nn_input
        else:       #  isScalerActivated=True
            nn_input = np.vstack( (Hi_vec, Hi_BS_vec, Qi_vec, Li_vec, VQ_local, VQ_remote) ).transpose().flatten()  # like [h1, hBS1, Q1, L1, h2, hBS2, Q2, L2, ...]
            if t <= training_interval: 
                nn_input_scale = np.vstack( (Hi_vec*CHFACT_UAV, Hi_BS_vec*CHFACT_BS, Qi_vec*QLFACT, Li_vec*QLFACT, VQ_local*QLFACT, VQ_remote*QLFACT) ).transpose().flatten()  # like [h1, hBS1, Q1, L1, h2, hBS2, Q2, L2, ...]
            else: 
                nn_input_scale = scaler.transform(nn_input[np.newaxis,:])[0]
            
    # generate a batch of feasible actions 
    if selection_mode == "learning":
        m_pred, m_list = mem.decode(nn_input_scale, n_actions, num_users=num_users)
    elif selection_mode == "exhausted search":
        m_pred = mem.decode(nn_input_scale, n_actions, num_users=num_users)[0]  # get the prediction of the neural network
        m_list = m_list_bf.copy() # get all feasible actions from BF search 
    elif selection_mode == "random":
        m_idx = np.random.choice(len(m_list_bf))
        m_list = m_list_bf[m_idx].copy().reshape(1,-1)       # equivalent to m_list = np.expand_dims(m_list_bf[idx], axis=0)])
    elif selection_mode == "greedy (qlen)":
        m_list = server.assign_subchannel_greedy_qlen(Qi_vec, Li_vec, VQ_local, VQ_remote)
    elif selection_mode == 'greedy (chgain)':
        m_list = server.assign_subchannel_greedy_chgain(Hi_vec, Hi_BS_vec)
        
    
    r_list = []         # all results of candidate offloading actions
    v_list = []         # the objective values of candidate offloading actions
    for m in m_list:
        ##### 2) Critic module: evaluate the offloading actions
        r_list.append(server.opt_task_offloading(Qi_vec, Li_vec, VQ_local, VQ_remote, Hi_vec, Hi_BS_vec, m[:num_users], m[num_users:]))  # return (fval, b_opt, pTx_user)
        v_list.append(r_list[-1][0])
        
    idx_best = np.argmin(v_list)                # index of the best offloading action
    k_idx_his.append(idx_best)                  # record the index of the smallest reward 
    alpha_opt = m_list[idx_best][:num_users]    # optimal action for the bw allocation of user-UAV link (alpha)
    beta_opt = m_list[idx_best][num_users:]     # optimal action for the bw allocation of user-macro BS link (beta)
    offvol_uav_opt = r_list[idx_best][1];       # optimal action for offloading decision for the UAV link (b), given the bandwidth allocation (m)
    offvol_mbs_opt = r_list[idx_best][2];       # optimal action for offloading decision for the mBS link (b), given the bandwidth allocation (m)
    bw_alloc_uav = r_list[idx_best][3]
    bw_alloc_mbs = r_list[idx_best][4]
    pTx_user = r_list[idx_best][5]              # optimal pTx of user, given the bandwidth allocation (m)
    
    ##### 3) Policy update module: update the policy
    if is_training_model==True:
        mem.encode(nn_input, m_list[idx_best], m_pred)  # remember the optimal action and learn if training interval have passed 
    mode_his.append(m_list[idx_best])
    
    # The UAV: update states
    if t+1 < time_max:
        qlen = server.qlen[:,t] - fcpu_uav_opt*slot_len/cycles_per_bit 
        server.qlen[:,t+1] = np.where( qlen >= 0, qlen, 0) + offvol_uav_opt*alpha_opt  
        vqlen = server.vq_qlen_penalty[:,t] + scale_vq * (server.qlen[:,t+1] - qlen_thres_uav)
        server.vq_qlen_penalty[:,t+1] = np.where( vqlen >= 0, vqlen, 0)   
    # server.pw_commun[time] = np.sum(cal_pTx_uav(beta_vec=beta_opt, fc_vec=fcpu_uav_opt, Hi_vec=Hi_vec)) # power -> do not count slot_len 
    # server.pw_comput[time] = server.ncores * kappa * (np.sum(fcpu_uav_opt)/server.ncores)**3            # do not count slot_len, tasks are equally shared by all cores  
    server.pw_comput[t] =  kappa * np.sum(fcpu_uav_opt**3)            
        
    # Users: offload tasks to MEC server(s) following instructions given by the UAV 
    for id, user in enumerate(users): 
        user.tasks_offloaded_to_server[t] = offvol_uav_opt[id] + offvol_mbs_opt[id]
        user.power_transmit[t] = pTx_user[id] 
        
        # Optimization for local computation at the user side 
        tasks_backlog = user.queue_length[t] - user.tasks_offloaded_to_server[t]
        assert tasks_backlog+1 >= 0, "Error: tasks_backlog < 0" 
        tasks_backlog = np.where(tasks_backlog > 0, tasks_backlog, 0) 
        fcpu_local, pw_local, task_local = user.opt_fcpu_local(t, tasks_backlog, VQ_local[id])           
        
        user.cpu_frequency[t] = fcpu_local 
        user.power_local_computation[t] = pw_local         
        user.tasks_computed_locally[t] = task_local   
        user.update_queue(t)    # update user.queue_length[t+1] and user.vq_qlen_penalty[t+1]
        user.update_power(t)    # update user.pw_total[t]
    
    
    # Calculate moving-average of the system energy consumption   
    energy_sys_tmp = 0 
    rolling_interval_e = 300      
    if t < rolling_interval_e: 
        t0 = 0
    else: 
        t0 = t - rolling_interval_e
    for id, user in enumerate(users):
           energy_sys_tmp = energy_sys_tmp + psi_user[id]*np.mean( user.pw_total[t0:t])
    energy_sys_tmp = energy_sys_tmp + psi_uav*np.mean(server.pw_comput[t0:t]) 
    
    
    # For tracking 
    np.set_printoptions(precision=3) 
    scale_qlen = 1e6 
    if t % training_interval == 0 or t == time_max-1:
        if is_training_model == True and t >= training_interval: 
            print("\ntime = {x}/{tmax:.0f} \ttrain loss = {y:.2f} \ttest loss = {z:.2f} \tenergy({w}) = {e:.0f} mW".format(
                x=t, tmax=num_slots,  y=mem.cost_his[-1], z=mem.test_cost_his[-1], w=rolling_interval_e, e=energy_sys_tmp/1e-3 ))
        else: 
            print("\ntime = {}".format(t))
        print('qlen_user =\t', Qi_vec/scale_qlen, 'Mb', ', average=', np.mean(Qi_vec/scale_qlen), ' Mb,', f"thres={np.mean(qlen_thres_user)/scale_qlen} Mb")
        print('qlen_uav = \t', Li_vec/scale_qlen, 'Mb', ', average=', np.mean(Li_vec/scale_qlen), ' Mb,', f"thres={np.mean(qlen_thres_uav)/scale_qlen} Mb")
        print('vqlen (local) = ', VQ_local/scale_qlen)
        print('vqlen (remote) = ', VQ_remote/scale_qlen)
            
    if test_mode==True and t % training_interval == 0 :    
        # print(f'\ntime = {t*slot_len}/{total_time}s, Vlya =', "{:.1e}".format(Vlyapunov), ', Amean = ', f"{Amean/scale_qlen} Mbps" )
        print(f'\ntime = {t}/{int(num_slots)}, Vlya =', "{:.1e}".format(Vlyapunov), ', Amean = ', f"{Amean/scale_qlen} Mbps")
        print("\tenergy(UTD) = {e:.0f} mW".format(e=energy_sys_tmp/1e-3 ))
        print('qlen_user =\t', Qi_vec/scale_qlen, 'Mb', ', average=', np.mean(Qi_vec/scale_qlen), ' Mb,', f"thres={np.mean(qlen_thres_user)/scale_qlen} Mb")
        print('qlen_uav = \t', Li_vec/scale_qlen, 'Mb', ', average=', np.mean(Li_vec/scale_qlen), ' Mb,', f"thres={np.mean(qlen_thres_uav)/scale_qlen} Mb")
        print('vqlen (local) = \t', VQ_local/scale_qlen)
        print('vqlen (remote) = \t', VQ_remote/scale_qlen)
        task_local = np.array([user.tasks_computed_locally[t] for user in users])
        print('tasks offloaded to uav =\t', offvol_uav_opt/scale_qlen, 'Mb,', 'sum = ', np.around(np.sum(offvol_uav_opt/scale_qlen), decimals=3), 'Mb')
        print('tasks offloaded to mbs =\t', offvol_mbs_opt/scale_qlen, 'Mb,', 'sum = ', np.around(np.sum(offvol_mbs_opt/scale_qlen), decimals=3), 'Mb')
        print('tasks c.locally =\t', task_local/scale_qlen, 'Mb,', 'sum = ', np.around(np.sum(task_local/scale_qlen), decimals=3), 'Mb')
        task_remote = fcpu_uav_opt*slot_len/cycles_per_bit
        print('tasks c.remotely =\t', task_remote/scale_qlen, 'Mb,', 'sum = ', np.around(np.sum(task_remote/scale_qlen), decimals=3), 'Mb')
        task_arrival = np.array([user.arrival_task[t] for user in users])
        print('task arrival =\t', task_arrival/scale_qlen, 'Mb,', 'sum = ', np.around(np.sum(task_arrival/scale_qlen), decimals=3), 'Mb')
        
        print('Hi (UAV)=\t', Hi_vec, 'dB')
        print('Hi (BS) =\t', Hi_BS_vec, 'dB')
        print('alpha (UAV) = \t', m_list[k_idx_his[-1]][:num_users], ', sum=', np.sum(m_list[k_idx_his[-1]][:num_users]))
        print('beta (BS) = \t', m_list[k_idx_his[-1]][num_users:], ', sum=', np.sum(m_list[k_idx_his[-1]][num_users:]))
        print('bw_alloc_uav=\t', bw_alloc_uav, 'sum=', np.sum(bw_alloc_uav))
        print('bw_alloc_mbs=\t', bw_alloc_mbs, 'sum=', np.sum(bw_alloc_mbs))
        fcpu_user = np.array([user.cpu_frequency[t] for user in users])
        print('fcpu_user =\t', fcpu_user/1e9, 'GHz', ', sum=', np.around(np.sum(fcpu_user/1e9), decimals=3), 'GHz')
        print('fcpu_uav = \t', fcpu_uav_opt/1e9, 'GHz', ', sum=', np.around(np.sum(fcpu_uav_opt/1e9), decimals=3), 'GHz')
        
        pw_commun_user = np.round([user.power_transmit[t]/1e-3 for user in users])
        pw_comput_user = np.round([user.power_local_computation[t]/1e-3 for user in users])
        print('pw_user(commun) = \t', pw_commun_user, 'mW,', 'sum =', np.sum(pw_commun_user), 'mW', ', avg=', np.mean(pw_commun_user), 'mW')
        print('pw_user(comput) = \t', pw_comput_user, 'mW,', 'sum = ', np.sum(pw_comput_user), 'mW', ', avg=', np.mean(pw_comput_user), 'mW')
        pw_server = kappa * fcpu_uav_opt**3
        print('pw_uav(comput) = \t', pw_server/1e-3 , 'mW,', 'sum =', np.round(np.sum(pw_server)/1e-3), 'mW')
        assert np.all(task_local + offvol_uav_opt + offvol_mbs_opt <= Qi_vec+1), "Error: task_local + task_offload > Qi_vec"
        assert np.all(task_remote <= Li_vec+1), "Error: task_remote > Li_vec"
        print('\n')

run_time=timer.time()-t_start
print("\n\nSimulation finished.")
print("Simulation time = {t:.2f}s".format(t=run_time))


''' 
-----------------------------------------------------
Calculate KPIs and plot figures for each user
-----------------------------------------------------
'''  
import matplotlib.pyplot as plt 

# Plot tranning loss
if is_training_model == True: 
    # mem.plot_cost()
    plt.figure()    # create a figure 
    plt.plot(np.arange(len(mem.cost_his))*mem.training_interval, mem.cost_his, '-b', label='Train Loss')
    plt.plot(np.arange(len(mem.cost_his))*mem.training_interval, mem.test_cost_his, '-r', label='Test Loss')
    plt.ylabel('Loss')
    plt.xlabel('Time')
    plt.grid(True) 
    plt.legend()
    plt.title(selection_mode)
    plt.savefig(mypath + f'/train_loss.png')


for id, user in enumerate(users):
    Qi = user.queue_length
    Ai = user.arrival_task
    task_local = user.tasks_computed_locally            # tasks computed locally 
    task_offload = user.tasks_offloaded_to_server       # tasks offloaded to server 
    stats = [Qi,Ai,task_local,task_offload]

    plt.figure()    # create a figure 
    plt.plot(export_moving_average(Qi/1e6),label="qlen (local)")
    plt.plot(export_moving_average(Ai/1e6),label="arrival tasks")
    plt.plot(export_moving_average(task_local/1e6),label='local tasks')
    plt.plot(export_moving_average(task_offload/1e6),label='offloaded tasks')  
    plt.plot(export_moving_average(server.qlen[id,:]/1e6), label='qlen (remote)') 
    plt.plot(export_moving_average(user.vq_qlen_penalty/1e6), label="vqlen (local)")
    plt.plot(export_moving_average(server.vq_qlen_penalty[id,:]/1e6), label="vqlen (remote)")
    plt.legend()
    plt.grid(True)
    plt.title(f"users[{id}]") 
    plt.xlabel("time")
    plt.ylabel("stats (in Mbits)")
    plt.xticks(np.arange(0,time_max,step=time_max/10,dtype=int))
    plt.title(selection_mode)
    plt.savefig(mypath + f'/user{id}.png')
 

''' 
-----------------------------------------------------
Exporting simulation results to files 
and plot figures of moving averages of KPIs 
-----------------------------------------------------
'''  
moving_window_size = 100

##### Saving data
save_data(users, os.path.join(mypath, "users.pickle"))
save_data(server, os.path.join(mypath, "server.pickle"))
print('Saved figures and data of each user.')  

##### Save the DNN model
if is_training_model==True:
    model_json = mem.model.to_json()  # serialize model to JSON
    with open(os.path.join(models_folder, "memoryTF2conv, train={x} by {mode}.json".format(x=total_time, mode=selection_mode)), "w") as json_file:
        json_file.write(model_json)
    mem.model.save_weights(os.path.join(models_folder, "memoryTF2conv, train={x} by {mode}.h5".format(x=total_time, mode=selection_mode))) # serialize weights to HDF5
    print("Saved the trained model.")
        
    # export the memory 
    data = {'memory': mem.memory}
    save_data(data, os.path.join(mypath, "memory.pickle"))
    print(f"Saved the memory for training to a pickle file.")


# Plot moving averages of KPIs
Qlen_users = np.array([user.queue_length for user in users]).reshape(num_users,-1)  # shape = (num_uer, time_max)
Qlen_uav = server.qlen.reshape(num_users,-1) # shape = (num_uer, time_max)
Energy_users = np.array([user.pw_total for user in users]).reshape(num_users,-1)  # shape = (num_uer, time_max)
Energy_uav = (server.pw_commun + server.pw_comput) # shape = (time_max,)
Energy_sys = np.sum(psi_user.reshape(num_users,1)*Energy_users, axis=0) + psi_uav*Energy_uav # shape = (time_max,)
vqlen_local = np.array([user.vq_qlen_penalty for user in users]).reshape(num_users,-1)  # shape = (num_uer, time_max)
vqlen_remote = server.vq_qlen_penalty.reshape(num_users,-1) # shape = (num_uer, time_max)
plot_moving_average(np.mean(Qlen_users, axis=0)/1e6, rolling_intv=moving_window_size, ylabel='Average Data Queue of Users, Qi (Mb)', filepath=mypath, title=selection_mode)
plot_moving_average(np.mean(Qlen_uav, axis=0)/1e6, rolling_intv=moving_window_size, ylabel='Average Data Queue of UAV, Li (Mb)', filepath=mypath, title=selection_mode)
plot_moving_average(np.mean(Energy_users, axis=0)/1e-3, rolling_intv=moving_window_size, ylabel='Average Energy Consumption of Users, Ei (mW)', filepath=mypath, title=selection_mode)
plot_moving_average(Energy_uav/1e-3, rolling_intv=moving_window_size, ylabel='Average Energy Consumption of UAV, Euav (mW)', filepath=mypath, title=selection_mode)
plot_moving_average(Energy_sys/1e-3, rolling_intv=moving_window_size, ylabel='Average Energy Consumption of System (Weighted Sum), Esys (mW)', filepath=mypath, title=selection_mode)
plot_moving_average(np.mean(vqlen_local, axis=0)/1e6, rolling_intv=moving_window_size, ylabel='Average VQlen of Users, vqlen_local (Mb)', filepath=mypath, title=selection_mode)
plot_moving_average(np.mean(vqlen_remote, axis=0)/1e6, rolling_intv=moving_window_size, ylabel='Average VQlen of UAV, vqlen_remote (Mb)', filepath=mypath, title=selection_mode)
print('Plotted figures of moving averages of KPIs.')


# Export moving averages of KPIs to a pickle file 
data = {'Qlen_users (Mb)': Qlen_users/1e6, 
        'Qlen_uav (Mb)': Qlen_uav/1e6, 
        'Energy_users (mW)': Energy_users/1e-3, 
        'Energy_uav (mW)': (Energy_uav/1e-3).reshape(1,-1), 
        'Energy_sys (mW)': (Energy_sys/1e-3).reshape(1,-1),
        'VQlen_local (Mb)': vqlen_local/1e6,
        'VQlen_remote (Mb)': vqlen_remote/1e6
        }
save_data(data, os.path.join(mypath, "{x}.pickle".format(x=dir_name)))
print(f'Exported moving averages of KPI to a pickle file')


# Export system parameters to a text file (metadata) 
metadata={
    "num of slots": int(num_slots), 
    "slot duration (s)": slot_len,
    "num of users" : num_users, 
    "bandwidth (MHz)" : bw_uplink/1e6, 
    "limit channel of UAV": limit_channel_UAV, 
    "limit channel of mBS": limit_channel_BS, 
    "Arrival rate (Mbps)": Amean/1e6, 
    "task model": task_mode,
    "fcpu_max of user (GHz)": fcpu_max/1e9,
    "fcpu_max of one core of UAV (GHz)": fcpu_core_uav_max/1e9, 
    "Vlya (dB)": to_dB(Vlyapunov),
    "psi_uav": psi_uav, 
    "psi_user": psi_user, 
    "qthres for user (kb)": qlen_thres_user/1e3, 
    "qthres for uav (kb)": qlen_thres_uav/1e3, 
    "learning rate": learning_rate, 
    "num of actions": n_actions,
    "training interval": training_interval,
    "memory size": Memory, 
    "batch size": batch_size, 
    "std_var for generating actions": stdvar_gen_action, 
    "server selection mode" : selection_mode, 
    "dual connectivity": dual_connectivity, # True/False  
    "runtime (sec)": run_time   # simulation time in seconds 
}

with open(os.path.join(mypath, "system_parameters.txt"), 'w') as f: 
    for key, value in metadata.items(): 
        f.write('%s: %s\n' % (key, value)) 
        

print(f'Exported meta data to a txt file.')
print(f'Folder path: "{mypath}"')